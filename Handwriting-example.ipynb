{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 繁體中文字辨識\n",
    "\n",
    "### 事前準備\n",
    "* 請先至https://github.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset 下載資料\n",
    "* 四個壓縮檔解壓縮至raw資料夾\n",
    "\n",
    "* 也可使用AI FREE TEAM所提供的Data_Deployment_local.ipynb，\n",
    "* 這樣dataloader就要修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from sys import stdout\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP1: <br>\n",
    "給定每個中文字一個ID，存放在class_map字典中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_img_dir = 'data/raw'\n",
    "images = os.listdir(raw_img_dir)\n",
    "classes = set([x.split('_')[0] for x in images])\n",
    "class_map = {i: j for i, j in zip(classes, range(len(classes)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP2: <br>\n",
    "客製Dataset，回傳PIL讀取圖片的矩陣跟class_map內對應的ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, img_list, img_dir, n_class=len(classes), label_dict=class_map, trans=None):\n",
    "        self.images = img_list\n",
    "        self.images_dir = img_dir\n",
    "        self.n_classes = n_class\n",
    "        self.label = [x.split('_')[0] for x in img_list]\n",
    "        self.labels_map = label_dict\n",
    "        self.transform = trans\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_name = self.images[item]\n",
    "        label = self.labels_map[self.label[item]]\n",
    "        img = Image.open(os.path.join(self.images_dir, img_name))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP3: <br>\n",
    "建立DL模型，也可使用Pre Train Model，<br>\n",
    "這邊只跑了HelloCNN，<br>\n",
    "另外兩個模型是想要比較Batch Normalization在Activation Function前後的差異。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelloCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HelloCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(256, 32, kernel_size=1, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 4803),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = torch.mean(x.view(x.size(0), x.size(1), -1), dim=2)\n",
    "        out = self.classifier(x)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class HelloCNNwithBNbeforeRelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HelloCNNwithBNbeforeRelu, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(256, 32, kernel_size=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 4803),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = torch.mean(x.view(x.size(0), x.size(1), -1), dim=2)\n",
    "        out = self.classifier(x)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    class HelloCNNwithBNafterRelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HelloCNNwithBNafterRelu, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 32, kernel_size=1, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3200, 4803),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = torch.mean(x.view(x.size(0), x.size(1), -1), dim=2)\n",
    "        out = self.classifier(x)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP4:<br>\n",
    "建立訓練流程。<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        since_ = time.time()\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            # epoch init\n",
    "            sample_size = 0\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in data_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                sample_size += len(labels)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                # print log\n",
    "                stdout.write(\n",
    "                    '\\r%s' %\n",
    "                    '[{:5d}/{} ({:.1f}%)]\\tLoss: {:.4f}\\t Acc: {:.5f}\\t'.format(\n",
    "                        sample_size,\n",
    "                        dataset_sizes[phase],\n",
    "                        100.0 * sample_size / dataset_sizes[phase],\n",
    "                        loss.item(),\n",
    "                        running_corrects.double() / sample_size)\n",
    "                )\n",
    "                stdout.flush()\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print()\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        t_ = time.time() - since_\n",
    "        print()\n",
    "        print('Epoch Time Costs: {:.0f}m {:.0f}s'.format(t_ // 60, t_ % 60))\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP5:<br>\n",
    "切分訓練集與驗證集，這邊還沒切測試集，不過應該要切三組才正常。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(images)\n",
    "train_image = images[:int(len(images)*0.8)]\n",
    "valid_image = images[int(len(images)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sets = {\n",
    "    'train': train_image,\n",
    "    'valid': valid_image,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "這組資料集所有圖片都是50\\*50，<br>\n",
    "如果要用遷移學習，可依照各Pre train model的input shape做修改。<br>\n",
    "例如VGG改成(224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP6:<br>\n",
    "建立transforms，丟入MakeData做資料轉換。<br>\n",
    "最少須包含ToTensor()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((52, 52)),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.RandomRotation(degrees=5),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = {\n",
    "    x: MakeDataset(image_sets[x], raw_img_dir, trans=data_transforms[x])\n",
    "    for x in ['train', 'valid']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP7:<br>\n",
    "建立data loader。<br>\n",
    "依照GPU的RAM以及網路參數量調整batch_size。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {x: DataLoader(image_dataset[x],\n",
    "                              batch_size=32,\n",
    "                              shuffle=True if x == 'train' else False)\n",
    "                for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_dataset[x]) for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "STEP8:<br>\n",
    "抓取現在GPU狀況。<br>\n",
    "用.to(device)會比.cuda()好一些，<br>\n",
    "在沒有GPU的環境才不用再修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    HelloCNN(),\n",
    "    HelloCNNwithBNbeforeRelu(),\n",
    "    HelloCNNwithBNafterRelu(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = HelloCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]           1,792\n",
      "         LeakyReLU-2           [-1, 64, 48, 48]               0\n",
      "            Conv2d-3          [-1, 128, 46, 46]          73,856\n",
      "         LeakyReLU-4          [-1, 128, 46, 46]               0\n",
      "         MaxPool2d-5          [-1, 128, 23, 23]               0\n",
      "            Conv2d-6          [-1, 128, 21, 21]         147,584\n",
      "         LeakyReLU-7          [-1, 128, 21, 21]               0\n",
      "            Conv2d-8          [-1, 256, 19, 19]         295,168\n",
      "         LeakyReLU-9          [-1, 256, 19, 19]               0\n",
      "           Conv2d-10           [-1, 32, 21, 21]           8,224\n",
      "        LeakyReLU-11           [-1, 32, 21, 21]               0\n",
      "        MaxPool2d-12           [-1, 32, 10, 10]               0\n",
      "           Linear-13                 [-1, 4803]      15,374,403\n",
      "================================================================\n",
      "Total params: 15,901,027\n",
      "Trainable params: 15,901,027\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 9.45\n",
      "Params size (MB): 60.66\n",
      "Estimated Total Size (MB): 70.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_ft, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "[200569/200569 (100.0%)]\tLoss: 2.5186\t Acc: 0.22161\t\n",
      "train Loss: 5.1077 Acc: 0.2216\n",
      "[50143/50143 (100.0%)]\tLoss: 2.2275\t Acc: 0.52623\t\n",
      "valid Loss: 2.2442 Acc: 0.5262\n",
      "\n",
      "Epoch Time Costs: 24m 0s\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "[200569/200569 (100.0%)]\tLoss: 1.1071\t Acc: 0.72927\t\n",
      "train Loss: 1.1596 Acc: 0.7293\n",
      "[50143/50143 (100.0%)]\tLoss: 1.2863\t Acc: 0.71117\t\n",
      "valid Loss: 1.2912 Acc: 0.7112\n",
      "\n",
      "Epoch Time Costs: 22m 42s\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[200569/200569 (100.0%)]\tLoss: 0.3431\t Acc: 0.87107\t\n",
      "train Loss: 0.4999 Acc: 0.8711\n",
      "[50143/50143 (100.0%)]\tLoss: 1.0514\t Acc: 0.75069\t\n",
      "valid Loss: 1.1649 Acc: 0.7507\n",
      "\n",
      "Epoch Time Costs: 23m 2s\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[200569/200569 (100.0%)]\tLoss: 0.0206\t Acc: 0.96056\t\n",
      "train Loss: 0.1532 Acc: 0.9606\n",
      "[50143/50143 (100.0%)]\tLoss: 0.7820\t Acc: 0.80514\t\n",
      "valid Loss: 1.0390 Acc: 0.8051\n",
      "\n",
      "Epoch Time Costs: 23m 3s\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[200569/200569 (100.0%)]\tLoss: 0.0961\t Acc: 0.97171\t\n",
      "train Loss: 0.1099 Acc: 0.9717\n",
      "[50143/50143 (100.0%)]\tLoss: 0.7839\t Acc: 0.81351\t\n",
      "valid Loss: 1.0159 Acc: 0.8135\n",
      "\n",
      "Epoch Time Costs: 23m 9s\n",
      "\n",
      "Training complete in 115m 56s\n",
      "Best val Acc: 0.813513\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用簡單的架構做測試會有很大的Over-fitting，<br>\n",
    "可以加入一些解決over-fitting的作法，<br>\n",
    "例如BN或Dropout，<br>\n",
    "或是增加數據增強做法，<br>\n",
    "例如Cutout, Cutmix, Mixup等方法，https://zhuanlan.zhihu.com/p/104992391 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python_project\\venv\\torch\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type HelloCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "torch.save(model_ft, model_ft.__class__.__name__ + 'model.pkl')\n",
    "torch.save(model_ft.state_dict(), model_ft.__class__.__name__ + 'model_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
